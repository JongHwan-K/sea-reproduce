#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SEA ëª¨ë¸ ì¶”ë¡  ê²°ê³¼ì˜ ëª¨ë“  ë©”íŠ¸ë¦­ ì¶œë ¥
"""

import pickle
import numpy as np

def show_all_metrics():
    """ëª¨ë“  ë©”íŠ¸ë¦­ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
    
    # ê²°ê³¼ íŒŒì¼ ë¡œë“œ
    try:
        with open('results_fci_sergio_reproduce.pkl', 'rb') as f:
            results = pickle.load(f)
        print(f"âœ… ê²°ê³¼ íŒŒì¼ ë¡œë“œ ì„±ê³µ")
        print(f"ðŸ“Š ì´ ë°ì´í„°ì…‹ ìˆ˜: {len(results)}")
        print("="*80)
    except FileNotFoundError:
        print("âŒ results_fci_sergio_reproduce.pkl íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ëª¨ë“  ë°ì´í„°ì…‹ì˜ ëª¨ë“  ë©”íŠ¸ë¦­ ì¶œë ¥
    all_auc = []
    all_prc = []
    all_time = []
    
    print("ðŸ“‹ ê° ë°ì´í„°ì…‹ë³„ ìƒì„¸ ë©”íŠ¸ë¦­:")
    print("="*80)
    
    for i, (key, result) in enumerate(results.items()):
        print(f"\nðŸ” ë°ì´í„°ì…‹ {i+1}: {key}")
        print("-" * 60)
        
        # ê° ë°ì´í„°ì…‹ì˜ ê°œë³„ ë©”íŠ¸ë¦­
        for j in range(len(result['auc'])):
            auc_val = result['auc'][j]
            prc_val = result['prc'][j]
            time_val = result['time'][j].item() if hasattr(result['time'][j], 'item') else result['time'][j]
            
            print(f"  ìƒ˜í”Œ {j+1}: AUC={auc_val:.4f}, AUPRC={prc_val:.4f}, ì‹œê°„={time_val:.4f}ì´ˆ")
            
            # ì „ì²´ í†µê³„ìš© ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            all_auc.append(auc_val)
            all_prc.append(prc_val)
            all_time.append(time_val)
        
        # ê° ë°ì´í„°ì…‹ì˜ ìš”ì•½ í†µê³„
        dataset_auc_mean = np.mean(result['auc'])
        dataset_auc_std = np.std(result['auc'])
        dataset_prc_mean = np.mean(result['prc'])
        dataset_prc_std = np.std(result['prc'])
        dataset_time_mean = np.mean([t.item() if hasattr(t, 'item') else t for t in result['time']])
        dataset_time_std = np.std([t.item() if hasattr(t, 'item') else t for t in result['time']])
        
        print(f"  ðŸ“Š ë°ì´í„°ì…‹ ìš”ì•½: AUC={dataset_auc_mean:.4f}Â±{dataset_auc_std:.4f}, "
              f"AUPRC={dataset_prc_mean:.4f}Â±{dataset_prc_std:.4f}, "
              f"ì‹œê°„={dataset_time_mean:.4f}Â±{dataset_time_std:.4f}ì´ˆ")
    
    # ì „ì²´ í†µê³„
    print("\n" + "="*80)
    print("ðŸŽ¯ ì „ì²´ ì„±ëŠ¥ ìš”ì•½")
    print("="*80)
    print(f"ì´ ë°ì´í„°ì…‹ ìˆ˜: {len(results)}")
    print(f"ì´ ìƒ˜í”Œ ìˆ˜: {len(all_auc)}")
    print(f"í‰ê·  AUC: {np.mean(all_auc):.4f} Â± {np.std(all_auc):.4f}")
    print(f"í‰ê·  AUPRC: {np.mean(all_prc):.4f} Â± {np.std(all_prc):.4f}")
    print(f"í‰ê·  ì¶”ë¡  ì‹œê°„: {np.mean(all_time):.4f}ì´ˆ Â± {np.std(all_time):.4f}ì´ˆ")
    print(f"ì´ ì¶”ë¡  ì‹œê°„: {np.sum(all_time):.2f}ì´ˆ")
    print(f"ìµœê³  AUC: {np.max(all_auc):.4f}")
    print(f"ìµœê³  AUPRC: {np.max(all_prc):.4f}")
    print(f"ìµœì € AUC: {np.min(all_auc):.4f}")
    print(f"ìµœì € AUPRC: {np.min(all_prc):.4f}")
    print(f"ê°€ìž¥ ë¹ ë¥¸ ì¶”ë¡ : {np.min(all_time):.4f}ì´ˆ")
    print(f"ê°€ìž¥ ëŠë¦° ì¶”ë¡ : {np.max(all_time):.4f}ì´ˆ")
    
    # ì„±ëŠ¥ ë“±ê¸‰ ë¶„ë¥˜
    excellent_count = sum(1 for auc, prc in zip(all_auc, all_prc) if auc >= 0.9 and prc >= 0.7)
    good_count = sum(1 for auc, prc in zip(all_auc, all_prc) if auc >= 0.8 and prc >= 0.6 and not (auc >= 0.9 and prc >= 0.7))
    fair_count = sum(1 for auc, prc in zip(all_auc, all_prc) if auc >= 0.7 and prc >= 0.5 and not (auc >= 0.8 and prc >= 0.6))
    poor_count = len(all_auc) - excellent_count - good_count - fair_count

if __name__ == "__main__":
    show_all_metrics()
